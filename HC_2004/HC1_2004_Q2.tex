\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}



\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}

Higher Certificate, Paper I, 2004. Question 2

\begin{framed}
2. (i) The random variable X follows the Poisson distribution with probability mass function,    
\[ {\displaystyle f_X(x) =  P(X = x{\text{ events in interval}})=e^{-\lambda }{\frac {\lambda ^{x}}{x!}}} \qquad x = 0, 1, 2, \ldots .  \]


(a) Find the moment generating function of $X$. 
 
(b) Hence or otherwise show that the mean and variance of X are both equal to $\lambda$ . 
 
(c) State the Poisson approximation to the binomial distribution, indicating the circumstances in which it is appropriate.  
 
\end{framed}

The moment-generating function of a random variable X is 
\[{\displaystyle M_{X}(t) =\operatorname {E} \left[e^{tX}\right],\quad t\in \mathbb {R} ,} \]

wherever this expectation exists. In other words, the moment-generating function is the expectation of the random variable 
${\displaystyle e^{tX}} $
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
\item  The moment generating function is
%% Tidy Up Elsewhere

\[f(x) = e^{-\lambda} \frac{\lambda^x}{x!}, x=0,1,2,3 \ldots\]

%-------------------------------%

\begin{eqnarray*}
M_X(t) &=& E(e^{tX}) \\
&=& \sum^{\infty}_{x=0} e^{tX} \frac{e^{-\lambda}\lambda^{x}}{x!}\\
&=& \sum^{\infty}_{x=0} e^{-\lambda} \frac{\lambda e^t}{x!}\\
&=& exp(\lambda e^t - \lambda) \\
&=& exp(\lambda(e^t-1))
\end{eqnarray*}



\begin{eqnarray*}
E(x) 
&=& M_X^{\prime}(0) \\
&=& \left[ \lambda e^{t} e^{\lambda(e^t-1)} \right]_{t=0}\\
&=& \lambda
\end{eqnarray*}

\begin{eqnarray*}
E(X^2) 
&=& M_X^{\prime\prime}(0) \\
&=& \left[ \frac{d}{dt} \left( \lambda e^{t} e^{\lambda(e^t-1)} \right)\right]_{t=0}\\
&=& \left[ \lambda e^{t} e^{\lambda(e^t-1)}\lambda e^{t} + e^{\lambda(e^t-1)}\lambda e^{t}   \right]
&=& \lambda^2 + \lambda
\end{eqnarray*}

\begin{framed}
Product Rule \[ \frac{d(uv)}{dt} = u \frac{dv}{dt} +  v\frac{du}{dt}\]

\begin{itemize}
\item $u = \lambda e^{t}$  ${ \displaystyle \frac{du}{dt} = \lambda e^{t} }$
\item $v = e^{\lambda(e^t-1)}$  ${ \displaystyle \frac{dv}{dt} = e^{\lambda(e^t-1)}\lambda e^{t}}$ (remark: using chain rule)
\end{itemize} 
\end{framed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

.
\begin{itemize}
    \item Hence ( ) ( ) ( ) Var X = E X 2 − E X 2 =λ   .
    \item (Alternatively, the moments could be obtained from the power series
expansion of MX(t).)
    \item (Alternatively, though with comparatively lengthy algebra, the
moments could be obtained directly by $E(X) = \sum^{n}_{i=0}xP(X = x)$ and $E(X^2) =
\sum^{n}_{i=0}x^2P(X = x)$; or, somewhat easier, use \[E[X(X – 1)] = \sum^{n}_{i=0} x(x – 1)P(X = x)\]
(this is $\lambda^2$) and then 
\end{itemize}

\[Var(X) = E[X(X – 1)] + E(X) – [E(X)]^2.)\]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item  The binomial distribution with parameters n and p may be
approximated by the Poisson distribution with parameter np if n is large and p is small.
\begin{itemize}
    \item  As a "rule of thumb", ½ ≤ $np \leq 10$ gives an
indication of how large n should be and how small p should be. 
    \item If
$np > 10$, a Normal approximation to the binomial may be better.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%
\item  Let X = number of wrong calculations. We have $X \sim B(200, 0.0075)$.

\begin{eqnarray*}
P(X=1) &=& { 200 \choose 1}(0.0075)^1(0.9925)^{199} \\
&=& 0 \times  0.0075^4 0.9925^{196}\\
&=& 0.3353\\
\end{eqnarray*}

\begin{eqnarray*}
P(X=4) &=& { 200 \choose 4}(0.0075)^4(0.9925)^{196} \\
&=& \frac{200 199 198 197}{4 3 2 1} 0.00754 0.9925196\\
&=& 0.0468\\
\end{eqnarray*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{framed}
 
(ii) A civil servant calculates weekly social security payments for unemployed adults.  These payments vary according to claimants' circumstances, and errors may occur.  Over a long period of time, the probability of a wrong calculation has been found to be 0.0075.  Find to 4 decimal places the exact probability that a sample of 200 contains (a) 1 wrong calculation, (b) 4 wrong calculations. 
\end{framed}
\begin{framed}
Repeat part (ii) using the Poisson approximation to the binomial distribution.  In each case find to two significant figures the percentage error in the Poisson calculation.  Comment briefly on your results. 
\end{framed}
\end{framed}
\item  We approximate using $X \sim Poisson(200 × 0.0075 = 1.5)$. With this,
\[P( X =1) =1.5e^{−1.5} = 0.3347(0)\]
giving a percentage error of 

\[\frac{100(0.33532 - 0.33470)}{0.33532} = 0.18\%\]

−
= , and
( ) ( ) ( )
1.5 1.5 4
4 0.0470 7
4!
e
P X
−
= = =
giving a percentage error of 
\[\frac{100(0.04707  - 0.04680)}{0.04680} = 0.58\%\]

[Note. These percentage errors might come out slightly differently if more
accuracy is kept in the binomial and Poisson probabilities.]
\begin{itemize}
    \item Both approximations are remarkably accurate, with percentage errors well
below 1\%. 
\item The approximation for X = 1 (one wrong calculation) is the more
accurate of the two. 
\item That approximation is an underestimate; the other is an
overestimate.
\end{itemize}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
