\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}
%\usepackage{bigints}

\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}
  \begin{table}[ht!]
  \centering
  \begin{tabular}{|p{15cm}|}
  \hline
The random variable X is exponentially distributed with probability density function 
 
 \[{\displaystyle f(x;\lambda )={\begin{cases}\lambda e^{-\lambda x}&x\geq 0,\\0&x<0.\end{cases}}} 
\]

 
  where $\lambda > 0$. 
 
  Obtain the distribution function of X, F(x) say, and sketch the graphs of f(x) and F(x). 
 \\ \hline 
   \end{tabular}
 \end{table}
 



\begin{enumerate}[(a)]
 \item 
 
\begin{eqnarray*}
F(X) &=& P(X \leq x) \\ &=& \int^{x}_{0} \lambda e^{\lambda u} du\\
 &=& \left[-e^{-\lambda u}\right]^{x}_{0} \\ &=& 1-e^{-\lambda x} \qquad (x \geq  0)\\
\end{eqnarray*}

The cumulative distribution function is given by 
\[ {\displaystyle F(x;\lambda )={\begin{cases}1-e^{-\lambda x}&x\geq 0,\\0&x<0.\end{cases}}} \]


\newpage
\subsection*{Maximum likelihood}
The likelihood function for $\lambda$, given an independent and identically distributed sample $x = (x_1, \ldots, x_n)$ drawn from the variable, is: 
\[ {\displaystyle L(\lambda )=\prod _{i=1}^{n}\lambda \exp(-\lambda x_{i})=\lambda ^{n}\exp \left(-\lambda \sum _{i=1}^{n}x_{i}\right)=\lambda ^{n}\exp \left(-\lambda n{\overline {x}}\right),} \]

where: 
\[ {\displaystyle {\overline {x}}={1 \over n}\sum _{i=1}^{n}x_{i}} \]

is the sample mean. 
The derivative of the likelihood function's logarithm is: 
\[ {\displaystyle {\frac {\mathrm {d} }{\mathrm {d} \lambda }}\ln(L(\lambda ))={\frac {\mathrm {d} }{\mathrm {d} \lambda }}\left(n\ln(\lambda )-\lambda n{\overline {x}}\right)={\frac {n}{\lambda }}-n{\overline {x}}\ {\begin{cases}>0,&0<\lambda <{\frac {1}{\overline {x}}},\\[8pt]=0,&\lambda ={\frac {1}{\overline {x}}},\\[8pt]<0,&\lambda >{\frac {1}{\overline {x}}}.\end{cases}}} 
\]
Consequently, the maximum likelihood estimate for the rate parameter is: 
\[ {\displaystyle {\widehat {\lambda }}={\frac {1}{\overline {x}}}={\frac {n}{\sum _{i}x_{i}}}} \]

Although this is not an unbiased estimator of 
${\displaystyle \lambda } $
, ${\displaystyle {\overline {x}}}$ 
 is an unbiased[4] MLE[5] estimator of 
${\displaystyle 1/\lambda =\beta ,} $
 where 
${\displaystyle \beta } $
 is the scale parameter defined in the 'Alternative parameterization' section above and the distribution mean. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
  \begin{table}[ht!]
  \centering
  \begin{tabular}{|p{15cm}|}
  \hline 
 (ii) Given a random sample $x_1,\ldots,x_n$ from this distribution, write down the likelihood function and show that the maximum likelihood estimate of $\lambda$ , $\hat{\lambda}$  say, is the reciprocal of the sample mean. 
\\ \hline 
   \end{tabular}
 \end{table}
%%%%%%%%%%%%%%%%%%%%%%%% 
 \item  \begin{eqnarray*}
L  &=& \prod^{n}_{i=1} \lambda e^{-\lambda x_i} \\
 &=& \lambda^n exp( - \lambda \sum^n_{i=1} x_i) \\
 &=& \lambda_n e^{-n\lambda \bar{x}} ) \ln L \\
&=& n \ln \lambda -n \lambda \bar{x}
\end{eqnarray*}

\[\frac{d}{d \lambda}(\ln(L)) = \frac{1}{\lambda} -  n \bar{x} = 0\] for 
$\hat{\lambda} = \frac{1}{\bar{x}}$

\[\frac{d^2}{d \lambda^2}(\ln(L)) = \frac{n}{\lambda^2}\] 

${\displaystyle \frac{d^2}{d \lambda^2}(\ln(L)) < 0  }$ for all $\lambda$, so there
is a maximum for $\hat{\lambda}$
so there is a maximum for $\hat{\lambda}$¸

%%%%%%%%%%%%%%%%%%%%%%%%%

 
  \begin{table}[ht!]
  \centering
  \begin{tabular}{|p{15cm}|}
  \hline 
\noindent \textbf{Part (c)} \\Show that the second derivative of the log-likelihood with respect to $\lambda$ is 
given by 
 
\[  \frac{d^2\ln L}{d\lambda^2} = - \frac{n}{\lambda^2} \]
 
  You are given that, if $n$ is large, 
 
 \[ \hat{\lambda} \sim N \left(\lambda , - \left[\frac{d^2\ln L}{d\lambda^2}   \right] ^{-1}   \right) \mbox{approximately}.    \]  
 
  By replacing $\lambda$ by $\hat{\lambda}$  in the variance of this distribution, obtain an approximate 95\% confidence interval for $\lambda$ . 
  
\\ \hline 
   \end{tabular}
 \end{table}
\item  Using the result just found 
$\hat{\lambda} \sim N(\lambda, \lambda^2/n)$


$\hat{\lambda} \sim N(\lambda, 1/n(\bar{x})^2)$
 and so approximately
\[ \frac{\hat{lambda} - \lambda }{ (\bar{x} \sqrt{n})^{-1} } \sim N(0,1), \] from which an approximate 95\% confidence interval for $\lambda$ is given by
\[\lambda \pm 1:96=(x
p
n)\] or 1
x (1 § 1p:96
n )
\end{enumerate}
\end{document}
