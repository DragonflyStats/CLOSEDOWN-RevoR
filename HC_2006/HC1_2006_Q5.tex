\documentclass[a4paper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}

%\usepackage{bigints}
\usepackage{vmargin}

% left top textwidth textheight headheight

% headsep footheight footskip

\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}

\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}

\begin{document}
Higher Certificate, Paper I, 2006. Question 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------%

\begin{table}[ht!]
     
\centering
     
\begin{tabular}{|p{15cm}|}
     
\hline        

\noindent The random variable X follows a Poisson distribution with probability mass function
\[\frac{e^{-\lambda}\lambda^{x}}{x!}\]where $x=\{0,1,2,\ldots$ and $\lambda >0$.\\ \bigskip



(i) Show that $E(X) = Var(X) = \lambda$.
\\ \hline
      
\end{tabular}
    
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}[(a)]
\item 

\begin{multicols}{2}
\begin{eqnarray*}
E(X) &=&  \sum^{\infty}_{x=0} x \frac{e^{-\lambda}\lambda^{x}}{x!}  \\
&=&  \lambda e^{-\lambda}\sum^{\infty}_{x=0} \frac{\lambda^{x-1}}{(x-1)!}  \\
&=& \lambda e^{-\lambda} e^{\lambda}\\
&=& \lambda
\end{eqnarray*}

\begin{eqnarray*} E(X^2) &=& E[X(X-1) + X] \\ &=& E[X(X-1)] + E[X] 
\end{eqnarray*}
\end{multicols}

\begin{multicols}{2}
\begin{eqnarray*}
E(X-1) &=&  \sum^{\infty}_{x=0} x(x-1)\frac{e^{-\lambda}\lambda^{x}}{x!}  \\
&=&  \lambda^2 e^{-\lambda}\sum^{\infty}_{x=0} \frac{\lambda^{x-2}}{(x-2)!}  \\
&=& \lambda^2 e^{-\lambda} e^{\lambda}\\
&=& \lambda^2
\end{eqnarray*}

\begin{eqnarray*} E(X^2) &=& E[X(X-1)] + E[X] \\ &=& \lambda^2 + \lambda \end{eqnarray*}

\begin{eqnarray*}Var(X) &=& E[X^2] - (E[X])^2 \\ &=& (\lambda^2 + \lambda)- (\lambda^2) \end{eqnarray*}
\end{multicols}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{table}[ht!]
\centering

\begin{tabular}{|p{15cm}|}
\hline        

\noindent

(ii) Given a random sample of values $x_1, x_2, \ldots, x_n$ from this distribution, obtain the maximum likelihood estimator (MLE) of $\lambda$, say. $\hat{lambda}$
\\ \hline
      
\end{tabular}
    
\end{table}

\item  \[1!ixniieLx$\lambda$$\lambda$−==Π, \]and hence . 1loglogconstantniiLnx$\lambda$$\lambda$==−++Σ
logixdLnd$\lambda\]
\[\lambda$Σ∴=−+\] which on setting equal to zero gives that the maximum likelihood estimate is ˆixxn$\lambda$Σ==. [Consideration of $\frac{d^2(\lambda}{d}$  $22logdd$ confirms that this is a maximum: 222log0ixdLd$\lambda$$\lambda$−Σ=<.]







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht!]
\centering

\begin{tabular}{|p{15cm}|}
\hline        

\noindent
(iii) Write down $Var(\lambda)$ as a function of $\lambda$ , and hence find the MLE of $Var(\lambda)$. Show that a large-sample approximate
95\% confidence interval (CI) for $\lambda$ is given by 
\[\hat{\lambda} -  1.96  \sqrt{ \frac{\hat{\lambda} }{n} } \leq \lambda \leq  \hat{\lambda} +   1.96  \sqrt{ \frac{\hat{\lambda} }{n} }.\]
\\ \hline
      
\end{tabular}
    
\end{table}




\item  \[Var(\hat{\lambda}) = Var(\bar{X}) = \frac{Var(X)}{n} = \frac{\lambda}{n}.\]
Thus the maximum likelihood estimator of $Var(\hat{
\lambda)$ is $ \frac{ \lambda}{n}$.
\begin{itemize}
    \item By the central limit theorem, $\bar{X} = \hat{\lambda}$ is approximately Normally distributed with mean $\lambda$ and variance $\lambda$ /n. 
    \item We estimate the variance by ˆ
$\lambda$/n, so that we have ˆˆ~N,n$\lambda$$\lambda$$\lambda$⎛⎞⎜⎜⎝⎠, approximately.
\item Hence an approximate 95\% confidence interval is given by
\[0.95 \approx P \left( -1.96 \leq { \frac{ \hat{\lambda} - \lambda }{   \hat{lambda} / \sqrt{n} } }  \leq 1.96 \right) \]
leading to the interval \[\hat{\lambda} -  1.96  \sqrt{ \frac{\hat{\lambda} }{n} } \leq \lambda \leq  \hat{\lambda} +   1.96  \sqrt{ \frac{\hat{\lambda} }{n} }.\]
\end{itemize}


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\begin{table}[ht!]
\centering

\begin{tabular}{|p{15cm}|}
\hline        
\noindent

(iv) Assume that the numbers of books, $x_1, x_2, x_3, \ldots$, that go missing each month from the local library follow a Poisson 
distribution with unknown mean $\lambda$. The monthly numbers of missing books in 2005 were
\[ \{3, 7 ,2, 5, 8, 2, 4, 5, 4, 4 ,1, 3.\}\]
Use these data to calculate and an approximate 95\% CI for $\lambda$. Also compute the sample variance of the data; discuss 
briefly whether this computation supports, or throws doubt on, the Poisson model suggested (no formal test is required). $\hat{\lambda}$
\\ \hline
 
\end{tabular}
\end{table}
\item  For the given sample, we have n = 12 and Σxi = 48, leading to ˆ4x$\lambda$==. The approximate confidence interval is therefore
441.96to41.961212⎛⎞−+⎜⎟⎜⎟⎝⎠, i.e. 2.87 to 5.13.
The sample also gives $\sum(x_i)^2 = 238$; so the sample variance is
\[s2 = \frac{1}{11} \left( 238  - \frac{48^2}{12} \right)  = \frac{46}{11} = 4.182.\]
This is close to the sample mean (4), supporting a Poisson hypothesis for the underlying model.
\end{enumerate}
\end{document}
