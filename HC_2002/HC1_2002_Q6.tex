\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngpage}
%\usepackage{bigints}

\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{2.0cm}{2.5cm}{16 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.3}

\setcounter{MaxMatrixCols}{10}
\begin{document}
Higher Certificate, Paper I, 2002. Question 6
\begin{framed}
The random variable X follows the exponential distribution with rate
parameter λ, so that the probability density function (pdf) of X is given by
\[f(x;\lambda) = \begin{cases} \lambda e^{-\lambda x} & x \ge 0, \\ 0 & x < 0. \end{cases}\]
with $\lambda >0$


Show that the moment generating function of X, MX(t) say, is given by
( )
1
1 , , X
M t t t λ
λ
− =  −  <  
\[ {\displaystyle {\frac {\lambda }{\lambda -t}},{\text{ for }}t<\lambda }  \frac{\lambda}{\lambda-t}, \text{ for } t < \lambda \]
and hence show that the mean and variance of X are given by $1/\lambda$
λ
and $1/\lambda^2$
respectively.
\end{framed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
f (x) =λ e−λ x x > 0, λ > 0
\begin{enumerate}
\item ( ) ( )
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2002 HC1 Q6 Part i

\begin{eqnarray*}
M_X(t)  &=& E[ e^{tx}] \\
&=& \int^{\infty}_{0} \lambda e^{-\lambdax + tx} dx\\
&=& \int^{\infty}_{0} \lambda e^{-(\lambda-t)x} dx\\
&=&  \left[ - \frac{\lambda e^{-(\lambda-t)x}}{\lambda-t}  \right]^{\infty}_{0}\\
&=& \frac{1}{\lambda - t}\
&=& \left( 1 - \frac{t}{\lambda}\right)^{-1} \mbox{ where } |t| < \lambda  \\
\end{eqnarray*}

\[ M_x(t) = 1 + frac{t}{\lambda} + \frac{t^2}{\lambda^2}+ \ldots \]


${ \displaystyle E(X^k) = \mbox{ coefficent of } \frac{x^k}{k!} \mbox{ in the expansion } \}

Hence $E(X) = \frac{1}{\lambda}$; also $E(X^2) = \frac{2}{\lambda^2}$, and so $\operatorname{Var}(X) = \frac{2}{\lambda^2} - \left(\frac{1}{\lambda} \right)^2 = \frac{2}{\lambda^2}$
%=--------------------------------------%
% 2002 HC1 Q6 Part ii

L( \lambda|x_i,\ldots,x_n) = \prod^{n}_{i=1} \left( \lambda e^{-\lambda x_i}) 
 = \lambda^{n} exp \left (-\lambda \sum^{n}_{i=1} x_i \right)

${ \displaystyle  \ln L = n \ln \lambda - \lambda \sum^{n}_{i=1} x_i = n (\ln \lambda -\lambda \bar{x})  }$

${ \displaystyle  \frac{d (\log L)}{ d \lambda}  = \frac{n}{\lambda} -n \bar{x} \mbox{ for } \hat{lambda} = \frac{1}{\bar{x}} }$

${ \displaystyle  \frac{d^2 (\log L)}{ d \lambda^2}  = -\frac{n}{\lambda^2} }$ which confirms the maximum of $L$.


\begin{itemize}
\item E[Xk] = coefficient of
!
xk
k
in the expansion.
\item Hence E[X ] 1
λ
= ; also, 2
2
\item E X 2
λ
  = , so ( )
2
2 2
\item Var X 2 1 1
λ λ λ
= −   =  
 
.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{framed}
(ii) A random sample x1, …, xn is taken from this distribution. Obtain the
likelihood, L(λ), as a function of λ, and show that the maximum likelihood
estimate (MLE) of λ is given by
ˆ 1 ,
x
λ =
where x denotes the mean of the sample x1, …, xn.
\end{framed}

\item ( ) ( ) 1
1 1
| , ..., i exp
n n
x n
n i
i i
L λ x x λ e−λ λ λ x
= =
  = = − 
 
Π Σ .
ln ln (ln ) i L = n λ −λΣx = n λ −λ x
(ln )
0
d L n nx
dλ λ
= − = for ˆ 1
x
λ = .
2 ( )
2 2
d ln L n
dλ λ
= − which confirms maximum of L.

%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{framed}
(iii) By applying the central limit theorem to the distribution of X , or
otherwise, explain why
1 1.96 1 1.96
x x n x x n
− < λ < +
is an approximate 95% confidence interval for λ if n is large.

\end{framed}

\begin{framed}

A simple approximation to the exact interval endpoints can be derived using a normal approximation to the χ2
p,v distribution. This approximation gives the following values for a 95\% confidence interval: 
\[ {\displaystyle \lambda _{\text{lower}}={\widehat {\lambda }}\left(1-{\frac {1.96}{\sqrt {n}}}\right)\]
\[ {\displaystyle \lambda _{\text{upper}}={\widehat {\lambda }}\left(1+{\frac {1.96}{\sqrt {n}}}\right)}\]
This approximation may be acceptable for samples containing at least 15 to 20 elements.

\end{framed}
\item  

%-----------------------------------------%

The asymptotic variance of $\hat{\lambda}}$ [Cramer- Rao lower bound for variance] is given by
\[ \frac{1}{ E \left[ - \frac{d^2 (\log L)}{ d \lambda^2} \right] } \frac{n}{\lambda^2}\]


We have
2 ˆ approx N ,
n
λ λ λ
 
∼  
 
, i.e. the estimate of $SE(\hat{\lambda})$ is
ˆ
n
λ , so that
ˆ ˆ ˆ ˆ 1.96 1.96
n n
λ − λ <λ <λ + λ is an approximate 95\% confidence interval for λ when
n is large.
This is 1 1.96 1 1.96
x x n x x n
− <λ < + .
\end{enumerate}
\end{document}
